# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bg8yJM0OiTRwfeZ54PCnrN_uzzoTYRsc
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
# %pylab inline
import matplotlib.pyplot as plt
from IPython.core.interactiveshell import InteractiveShell
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn import metrics

from sklearn.metrics import accuracy_score 
from sklearn.metrics import confusion_matrix as cm

df=pd.read_csv('imdb_top_1000.csv')

df.head(3)

#Dataset Info
df.info()
print("Shape : ", df.shape)

#Drop columns like poster link, overview, series title as they may not impact the Gross revenue(target variable)
df.drop(columns=['Poster_Link','Overview','Series_Title'],inplace=True)

df.Gross.fillna(value='0', inplace=True)

# Brütteki ',' yerine boşluk bırakılıyor
df['Gross'] = df.Gross.apply(lambda x: int(x.replace(',','')))

# Calculating gross mean
Gross_mean=df.Gross.mean()/(len(df)-len(df[df.Gross==0]))
Gross_mean

# Replacing 0 with the gross mean
df.Gross.replace(to_replace=0,value=Gross_mean, inplace=True)

# Creating a set of all the unique genres.
Genre_list=set()

for row in df.Genre:
    Genre_list.update(row.strip().split(", "))

Genre_list

# Categorising the below as child restricted categories
Genre_child_prohibited=['Action','Crime','Horror','Mystery','Romance','Thriller','War','Western']

#Fill the missing values in Certificate using the genre column.If the Genre belongs to one of the child restricted ones
# fill with 'A' certificate
def fill(row):
    if pd.isna(row['Certificate']):
        for i in Genre_child_prohibited:
            if i in row['Genre']:
                row['Certificate']='A'
                break
    return row

df=df.apply(fill, axis=1)

#We see about 70 missing values in Certificate column is filled using above function
df.isna().sum()

# Filling remaining missing values using 'PG-13'
df.Certificate.fillna(value='PG-13', inplace=True)

#Concating the genre list as a new dataframe to the original dataframe
df_new=pd.concat([df,pd.DataFrame(columns=Genre_list, dtype=int)])

df_new.head()

# Filmler için ayrı türleri işaretleme işlevidef fill_values(row):
    Genre_list=row['Genre'].split(", ")
    for value in Genre_list:
        row[value]=1
    return row

df=df_new.apply(fill_values, axis=1)

df.drop(columns=['Star1','Star2','Star3','Star4','Genre'], inplace=True)

# Eksik değerlerin meta puan ortalaması ile doldurulması
df.Meta_score.fillna(value=df.Meta_score.mean(), inplace=True)

#Sayısal veri türüne dönüştürmek için çalışma zamanından 'min' kaldırılıyor
df['Runtime']=df['Runtime'].apply(lambda x:x.replace('min',''))

#Yayınlanan yılda 'PG' içeren satırı, yıl sütununda doldurulan uygunsuz veri olduğu için kaldırın
df[df['Released_Year']=='PG']
df.set_index('Released_Year', inplace=True)
df.drop(['PG'], inplace=True)

# Çalışma zamanı ve yayınlanan yılın veri türünü int'ye dönüştürün
df.reset_index(inplace=True)
df = df.astype({"Runtime": int, 'Released_Year':int})

# Kalan NaN değerlerinin 0 ile doldurulmasıdf.fillna(value=0, inplace=True)
df.fillna(value=0, inplace=True)

#Sertifika, Yönetmen, Genre_count kategorik sütunları için aptallar
df=pd.get_dummies(columns=['Certificate','Director'], drop_first=True, data=df)

df.head()

df.groupby('IMDB_Rating')['Gross'].count().plot()
xlabel('IMDB rating')
ylabel('Number of movies')

df.groupby('Runtime')['Gross'].mean().plot()
xlabel('Runtime (in minutes)')
ylabel('Gross Revenue (in 1 bn)')

df.groupby('Released_Year')['Gross'].count().plot()
xlabel('Released Year')
ylabel('Number of movies')

X = df.iloc[:, :-1].values
y = df.iloc[:, 1].values

df.shape

# tren, test 80:20'ye bölünür, hedef değişken Brüt gelirdir
target=df.Gross

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)
me_test1,me_test2= X_test,y_test

"""Linear Regresyon"""

model = LinearRegression()

model.fit(X_train,y_train)

tahmin = model.predict(X_test)

metrics.mean_absolute_error(y_test,tahmin)

np.sqrt(metrics.mean_squared_error(y_test,tahmin))

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier 

classifier = DecisionTreeClassifier(criterion = 'entropy', random_state=0)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

metrics.mean_absolute_error(y_test,y_pred)

np.sqrt(metrics.mean_squared_error(y_test,y_pred))

"""Random Forest"""

from sklearn.ensemble import RandomForestRegressor 

regressor = RandomForestRegressor(n_estimators=10, random_state=0)

regressor.fit(X_train, y_train)

RandomForest = regressor.predict(X_test)

metrics.mean_absolute_error(y_test,RandomForest)

np.sqrt(metrics.mean_squared_error(y_test,RandomForest))

"""KNN Algoritması"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train, y_train)

knnAlgoritması = knn.predict(X_test)

metrics.mean_absolute_error(y_test,knnAlgoritması)

np.sqrt(metrics.mean_squared_error(y_test,knnAlgoritması))

"""SVM algoritması"""

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

SVC = knn.predict(X_test)

metrics.mean_absolute_error(y_test,SVC)

np.sqrt(metrics.mean_squared_error(y_test,SVC))

from sklearn.ensemble import AdaBoostClassifier

adaboosts = AdaBoostClassifier(learning_rate=10)

adaboosts.fit(X_train, y_train)

adaboosts = adaboosts.predict(X_test)

metrics.mean_absolute_error(y_test,adaboosts)

np.sqrt(metrics.mean_squared_error(y_test,adaboosts))

from scipy.stats import pearsonr
from sklearn import datasets
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

model = PCA()
transformed_x = model.fit_transform(X)
#

transformed_df = pd.DataFrame(transformed)
transformed_df.corr(method = 'pearson')

plt.scatter(transformed[:,5], transformed[:,6])
plt.show

scaler = StandardScaler()
pipeline = make_pipeline(scaler, model)
pipeline.fit(X)

pca_features= PCA(n_components = 3)
dimension_reduction_result = pca_features.fit_transform(X)
dimension_reduction_result.shape

from sklearn.neural_network import MLPClassifier

ann = MLPClassifier(hidden_layer_sizes=(3,3,3,3))
ann.fit(X_train, y_train)

y_pred_ann = ann.predict(X_test,y_test)